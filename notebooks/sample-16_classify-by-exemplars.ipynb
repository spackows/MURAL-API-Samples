{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a large language model to classify sticky notes based on class exemplars\n",
    "\n",
    "### Scenario\n",
    "Imagine you are a team lead and you are taking your team through a reflection activity.  Your team has used a mural to collect thoughts about what things the team should stop doing, continue doing, and start doing.  Now, you need to cluster the sticky notes in the mural by category for further analysis.\n",
    "\n",
    "Notebook sections:\n",
    "\n",
    "**Section A - Explore prompting large languge models**\n",
    "- [Step 1: Set up IBM watsonx.ai foundation model Python library prerequisites](#step1)\n",
    "- [Step 2: Create a function for prompting a model to classify a message](#step2)\n",
    "\n",
    "**Section B - Set up your mural**\n",
    "- [Step 3: Set up MURAL prerequisites](#step3)\n",
    "- [Step 4: Read class names, exemplars, and feedback messages from your mural](#step4)\n",
    "\n",
    "**Section C - Classify sticky notes and move them together in the mural**\n",
    "- [Step 5: Classify sticky notes](#step5)\n",
    "- [Step 6: Move sticky notes into class boxes in the mural](#step6)\n",
    "\n",
    "When you run this notebook, your mural will look something like the following image:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/spackows/MURAL-API-Samples/main/images/sample-16_classify-by-exemplars_01.png\" width=\"50%\" title=\"Image of a mural\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A - Explore prompting large languge models\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/spackows/MURAL-API-Samples/main/images/sample-16_classify-by-exemplars_02.png\" width=\"60%\" title=\"Image of a mural\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "## Step 1: Set up IBM watsonx.ai foundation model Python library prerequisites\n",
    "Before you can prompt a foundation model in watsonx.ai, you must perform the following setup tasks:\n",
    "- 1.1 Create an instance of the Watson Machine Learning service\n",
    "- 1.2 Associate the Watson Machine Learning instance with the current project\n",
    "- 1.3 Create an IBM Cloud API key\n",
    "- 1.4 Create a credentials dictionary for Watson Machine learning\n",
    "- 1.5 Look up the current project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create an instance of the Watson Machine Learning service\n",
    "If you don't already have an instance of the IBM Watson Machine Learning service, you can create an instance of the service from the IBM Cloud catalog: <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\">Watson Machine Learning service</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Associate an instance of the Watson Machine Learning service with the current project\n",
    "The _current project_ is the project in which you are running this notebook.\n",
    "\n",
    "If an instance of Watson Machine Learning is not already associated with the current project, follow the instructions in this topic to do so: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html?context=wx&audience=wdp\" target=\"_blank\">Adding associated services to a project</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create an IBM Cloud API key\n",
    "Create an IBM Cloud API key by following these instruction: <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui#create_user_key\" target=\"_blank\">Creating an IBM Cloud API key</a>\n",
    "\n",
    "Then paste your new IBM Cloud API key in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cloud_apikey = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create a credentials dictionary for Watson Machine learning\n",
    "See: [Authentication](https://ibm.github.io/watson-machine-learning-sdk/setup_cloud.html#authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://ibm.github.io/watson-machine-learning-sdk/setup_cloud.html#authentication\n",
    "g_wml_credentials = { \n",
    "    \"url\"    : \"https://us-south.ml.cloud.ibm.com\", \n",
    "    \"apikey\" : g_cloud_apikey\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Look up the current project ID\n",
    "The _current project_ is the project in which you are running this notebook.  You can get the ID of the current project programmatically by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "g_project_id = os.environ[\"PROJECT_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "## Step 2: Create a function for prompting a model to classify sticky notes\n",
    "- 2.1 Experiment in Prompt Lab\n",
    "- 2.2 Specify your selected model ID, prompt parameters, and prompt text template\n",
    "- 2.2 Define a function to perform classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Experiment in Prompt Lab \n",
    "The Prompt Lab in watsonx.ai is a graphical interface for experimenting with prompting foundation models.\n",
    "\n",
    "Experiment in Prompt Lab to discover what works best:\n",
    "- Which model returns ideal results\n",
    "- What parameter settings (eg. decoding) work best\n",
    "- What prompt text causes the model to respond the way you want\n",
    "\n",
    "See: [Prompt Lab](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-prompt-lab.html?context=wx&audience=wdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Specify your selected model_id, prompt parameters, and prompt text template\n",
    "In the following three cells, there are example model ID, prompt parameters, and prompt text template you can use.\n",
    "\n",
    "Replace any of these with values you discovered while experimenting in Prompt Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example models:\n",
    "#\n",
    "# google/flan-ul2\n",
    "# google/flan-t5-xxl\n",
    "# bigscience/mt0-xxl\n",
    "# eleutherai/gpt-neox-20b\n",
    "# ibm/granite-13b-instruct-v1\n",
    "\n",
    "g_model_id = \"google/flan-t5-xxl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_prompt_parameters = {\n",
    "    \"decoding_method\" : \"greedy\",\n",
    "    \"min_new_tokens\"  : 0,\n",
    "    \"max_new_tokens\"  : 20\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "In the following example template, notice the use of `%s` as a placeholder for the class names, few-shot examples, and message text. \n",
    "\n",
    "If you replace this template with a prompt you discovered through your experiments in Prompt Lab, remember to include a placeholder for the class names, one for few-shot examples, and one for the message text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "g_prompt_template = \"\"\"Classify the message into one of three classes: %s\n",
    "\n",
    "%s\n",
    "\n",
    "Message: %s\n",
    "Class: \n",
    "\"\"\"\n",
    "\n",
    "def createBasePromptText( exemplars_arr ):\n",
    "    class_names_arr = []\n",
    "    exemplars_str = \"\"\n",
    "    index_arr = list( range( len( exemplars_arr ) ) )\n",
    "    random.shuffle( index_arr )\n",
    "    for i in index_arr:\n",
    "        class_name = exemplars_arr[i][\"class_name\"]\n",
    "        if( class_name not in class_names_arr ):\n",
    "            class_names_arr.append( class_name )\n",
    "        exemplars_str += \"Message: \" + exemplars_arr[i][\"message\"] + \"\\nClass: \" + class_name + \"\\n\\n\"\n",
    "    class_name_str = \", \".join( class_names_arr )\n",
    "    exemplars_str = re.sub( r\"\\s+$\", \"\", exemplars_str )\n",
    "    return g_prompt_template % ( class_name_str, exemplars_str, \"%s\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the message into one of three classes: Stop, Continue, Start\n",
      "\n",
      "Message: Stop having all-hands meetings, because they don't add any value.\n",
      "Class: Stop\n",
      "\n",
      "Message: Please keep the THINK-Thursday meeting-free afternoon!\n",
      "Class: Continue\n",
      "\n",
      "Message: I like the \"updates\" Slack channel - very efficient\n",
      "Class: Continue\n",
      "\n",
      "Message: Our daily stand-ups take too long.  Let's stop doing those.\n",
      "Class: Stop\n",
      "\n",
      "Message: At my friend's company, they have a lottery for plum parking spots.  We should do something similar!\n",
      "Class: Start\n",
      "\n",
      "Message: I think we should record our meetings so they could be played back\n",
      "Class: Start\n",
      "\n",
      "Message: We should take meeting minutes\n",
      "Class: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "g_test_exemplars_arr = [ \n",
    "    { \"class_name\" : \"Stop\",     \"message\" : \"Our daily stand-ups take too long.  Let's stop doing those.\" },\n",
    "    { \"class_name\" : \"Start\",    \"message\" : \"I think we should record our meetings so they could be played back\" },\n",
    "    { \"class_name\" : \"Continue\", \"message\" : \"I like the \\\"updates\\\" Slack channel - very efficient\" },\n",
    "    { \"class_name\" : \"Start\",    \"message\" : \"At my friend's company, they have a lottery for plum parking spots.  We should do something similar!\" },\n",
    "    { \"class_name\" : \"Continue\", \"message\" : \"Please keep the THINK-Thursday meeting-free afternoon!\" },\n",
    "    { \"class_name\" : \"Stop\",     \"message\" : \"Stop having all-hands meetings, because they don't add any value.\" }\n",
    "]\n",
    "g_test_message = \"We should take meeting minutes\"\n",
    "g_test_base_prompt_text = createBasePromptText( g_test_exemplars_arr )\n",
    "g_test_prompt_text = g_test_base_prompt_text % ( g_test_message )\n",
    "print( g_test_prompt_text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define a function to perform classification\n",
    "You can prompt foundation models in IBM watsonx.ai programmatically using the foundation models Python library.\n",
    "\n",
    "See:\n",
    "- <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-python-lib.html?context=wx&audience=wdp\" target=\"_blank\">Introduction to the foundation models Python library</a>\n",
    "- <a href=\"https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html\" target=\"_blank\">Foundation models Python library reference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"model_id\": \"google/flan-t5-xxl\",\n",
      "   \"created_at\": \"2023-11-11T02:59:41.349Z\",\n",
      "   \"results\": [\n",
      "      {\n",
      "         \"generated_text\": \"Start\",\n",
      "         \"generated_token_count\": 2,\n",
      "         \"input_token_count\": 165,\n",
      "         \"stop_reason\": \"eos_token\"\n",
      "      }\n",
      "   ],\n",
      "   \"system\": {\n",
      "      \"warnings\": [\n",
      "         {\n",
      "            \"message\": \"This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL. URL: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx\",\n",
      "            \"id\": \"disclaimer_warning\"\n",
      "         }\n",
      "      ]\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "import json\n",
    "\n",
    "test_model = Model( g_model_id, g_wml_credentials, g_prompt_parameters, g_project_id )\n",
    "\n",
    "test_response = test_model.generate( g_test_prompt_text )\n",
    "\n",
    "print( json.dumps( test_response, indent=3 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate( model_id, prompt_parameters, prompt_text, b_debug=False ):\n",
    "    model = Model( model_id, g_wml_credentials, prompt_parameters, g_project_id )\n",
    "    raw_response = model.generate( prompt_text )\n",
    "    if b_debug:\n",
    "        print( \"\\nraw_response:\\n\" + json.dumps( raw_response, indent=3 ) )\n",
    "    if ( \"results\" in raw_response ) \\\n",
    "       and ( len( raw_response[\"results\"] ) > 0 ) \\\n",
    "       and ( \"generated_text\" in raw_response[\"results\"][0] ):\n",
    "        return raw_response, raw_response[\"results\"][0][\"generated_text\"]\n",
    "    else:\n",
    "        print( \"\\nThe model failed to generate an answer\" )\n",
    "        print( \"\\nDebug info:\\n\" + json.dumps( raw_response, indent=3 ) )\n",
    "        return raw_response, \"\"\n",
    "\n",
    "def classifyMessage( model_id, prompt_parameters, base_prompt_text, message_text, b_debug=False ):\n",
    "    prompt_text = base_prompt_text % ( message_text )\n",
    "    if b_debug:\n",
    "        print( \"Prompt:\\n--------------------------START\")\n",
    "        print( prompt_text + \"--------------------------END\")\n",
    "    raw_response, generated_output = generate( model_id, prompt_parameters, prompt_text, b_debug )\n",
    "    class_name = generated_output.strip()\n",
    "    return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "--------------------------START\n",
      "Classify the message into one of three classes: Stop, Continue, Start\n",
      "\n",
      "Message: Stop having all-hands meetings, because they don't add any value.\n",
      "Class: Stop\n",
      "\n",
      "Message: Please keep the THINK-Thursday meeting-free afternoon!\n",
      "Class: Continue\n",
      "\n",
      "Message: I like the \"updates\" Slack channel - very efficient\n",
      "Class: Continue\n",
      "\n",
      "Message: Our daily stand-ups take too long.  Let's stop doing those.\n",
      "Class: Stop\n",
      "\n",
      "Message: At my friend's company, they have a lottery for plum parking spots.  We should do something similar!\n",
      "Class: Start\n",
      "\n",
      "Message: I think we should record our meetings so they could be played back\n",
      "Class: Start\n",
      "\n",
      "Message: We should take meeting minutes\n",
      "Class: \n",
      "--------------------------END\n",
      "\n",
      "raw_response:\n",
      "{\n",
      "   \"model_id\": \"google/flan-t5-xxl\",\n",
      "   \"created_at\": \"2023-11-11T02:59:58.362Z\",\n",
      "   \"results\": [\n",
      "      {\n",
      "         \"generated_text\": \"Start\",\n",
      "         \"generated_token_count\": 2,\n",
      "         \"input_token_count\": 165,\n",
      "         \"stop_reason\": \"eos_token\"\n",
      "      }\n",
      "   ],\n",
      "   \"system\": {\n",
      "      \"warnings\": [\n",
      "         {\n",
      "            \"message\": \"This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL. URL: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx\",\n",
      "            \"id\": \"disclaimer_warning\"\n",
      "         }\n",
      "      ]\n",
      "   }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Start'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifyMessage( g_model_id, g_prompt_parameters, g_test_base_prompt_text, g_test_message, b_debug=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B - Set up your mural\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/spackows/MURAL-API-Samples/main/images/sample-16_classify-by-exemplars_03.png\" width=\"50%\" title=\"Image of a mural\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "## Step 3: Set up MURAL prerequisites\n",
    "- 3.1 Create empty, sample mural\n",
    "- 3.2 Collect mural ID\n",
    "- 3.3 Get Oauth token\n",
    "- 3.4 Populate mural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create empty, sample mural\n",
    "In the MURAL web interface, create a new, empty mural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Collect mural ID\n",
    "You can find the mural ID in the url of a mural.\n",
    "\n",
    "Mural urls look something like this:\n",
    "\n",
    "```\n",
    "https://app.mural.co/t/<workspace>/m/<workspace>/<id>/...\n",
    "```\n",
    "\n",
    "What you need to pass to the MURAL API is just after the `/m/`: the \\<workspace> and the \\<id>.  And you need to join then with a period.\n",
    "\n",
    "For example, if you have a mural with this url:\n",
    "\n",
    "```\n",
    "https://app.mural.co/t/teamideas1234/m/teamideas1234/1234567890123/...\n",
    "```\n",
    "\n",
    "Then, the mural ID is: `teamideas1234.1234567890123`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_mural_id = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Collect OAuth token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_auth_token = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Populate mural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/spackows/MURAL-API-Samples/main/murals/sample-16_classify-by-exemplars.json\"\n",
    "response = urllib.request.urlopen( url )\n",
    "encoding = response.info().get_content_charset( \"utf8\" )\n",
    "sample_widgets_arr = json.loads( response.read().decode( encoding ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import copy\n",
    "\n",
    "def putWidget( auth_token, mural_id, widget ):\n",
    "    # https://developers.mural.co/public/reference/createstickynote\n",
    "    # https://developers.mural.co/public/reference/createtextbox\n",
    "    widget_type = \"textbox\" if ( \"text\" == widget[\"type\"] ) else widget[\"type\"]\n",
    "    url = \"https://app.mural.co/api/public/v1/murals/\" + mural_id + \"/widgets/\" + re.sub( \"\\s+\", \"-\", widget_type )\n",
    "    headers = { \"Accept\"        : \"application/json\", \n",
    "                \"Content-Type\"  : \"application/json\", \n",
    "                \"Authorization\" : \"Bearer \" + auth_token }\n",
    "    parms = copy.deepcopy( widget )\n",
    "    if \"id\" in parms:\n",
    "        del parms[\"id\"]\n",
    "    if \"type\" in parms:\n",
    "        del parms[\"type\"]\n",
    "    response = requests.request( \"POST\", url, headers = headers, json = parms )\n",
    "    response_json = json.loads( response.text )\n",
    "    msg = \"\"\n",
    "    if \"code\" in response_json:\n",
    "        msg += response_json[\"code\"] + \" \"\n",
    "    if \"message\" in response_json:\n",
    "        msg += response_json[\"message\"]\n",
    "    if msg != \"\":\n",
    "        print( \"[ \" + widget[\"id\"] + \" ] \" + msg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Quick!  After running this cell, switch to your browser \n",
    "# tab where the mural is to see the change\n",
    "# ...\n",
    "\n",
    "for widget in sample_widgets_arr:\n",
    "    putWidget( g_auth_token, g_mural_id, widget )\n",
    "print( \"Done!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step4\"></a>\n",
    "## Step 4: Read feedback and exemplars from your mural\n",
    "- 4.1 Read widgets from the mural\n",
    "- 4.2 Establish coordinates of class boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Read widgets from the mural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listWidgets( auth_token, mural_id ):\n",
    "    # https://developers.mural.co/public/reference/getmuralwidgets\n",
    "    url = \"https://app.mural.co/api/public/v1/murals/\" + mural_id + \"/widgets\"\n",
    "    headers = { \"Accept\": \"application/json\", \"Authorization\": \"Bearer \" + auth_token }\n",
    "    response = requests.request( \"GET\", url, headers = headers )\n",
    "    response_json = json.loads( response.text )\n",
    "    msg = \"\"\n",
    "    if \"code\" in response_json:\n",
    "        msg += response_json[\"code\"] + \" \"\n",
    "    if \"message\" in response_json:\n",
    "        msg += response_json[\"message\"]\n",
    "    if msg != \"\":\n",
    "        print( msg )\n",
    "        return None\n",
    "    if \"value\" not in response_json:\n",
    "        print( \"No value returned\" )\n",
    "        return None\n",
    "    return response_json[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_widgets_arr = listWidgets( g_auth_token, g_mural_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( json.dumps( g_widgets_arr, indent=3 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Establish coordinates of class boxes\n",
    "In the mural, there are three boxes, one box for each class: \"Stop\", \"Continue\", and \"Start\".\n",
    "\n",
    "To be able to move the sticky notes into the correct box by class, we need to know the coordinates of the boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWidgetsByType( widgets_arr ):\n",
    "    boxes_arr = []\n",
    "    labels_arr = []\n",
    "    stickies_arr = []\n",
    "    for widget in widgets_arr:\n",
    "        obj = { \"x\" : widget[\"x\"],\n",
    "                \"y\" : widget[\"y\"],\n",
    "                \"height\" : widget[\"height\"],\n",
    "                \"width\"  : widget[\"width\"] }\n",
    "        if( \"shape\" == widget[\"type\"] ):\n",
    "            boxes_arr.append( obj )\n",
    "        elif( \"text\" == widget[\"type\"] ):\n",
    "            obj[\"id\"]       = widget[\"id\"]\n",
    "            obj[\"text\"]     = re.sub( r\"\\<[^\\>]+\\>\", \"\", widget[\"text\"] )\n",
    "            labels_arr.append( obj )\n",
    "        elif( \"sticky note\" == widget[\"type\"] ):\n",
    "            obj[\"id\"]     = widget[\"id\"]\n",
    "            obj[\"text\"]   = widget[\"text\"]\n",
    "            obj[\"height\"] = widget[\"height\"]\n",
    "            obj[\"width\"]  = widget[\"width\"]\n",
    "            obj[\"x_org\"]  = widget[\"x\"]\n",
    "            obj[\"y_org\"]  = widget[\"y\"]\n",
    "            stickies_arr.append( obj )\n",
    "    return boxes_arr, labels_arr, stickies_arr\n",
    "\n",
    "def isInBox( widget, box ):\n",
    "    widget_left   = widget[\"x\"]\n",
    "    widget_right  = widget[\"x\"] + widget[\"width\"]\n",
    "    widget_top    = widget[\"y\"]\n",
    "    widget_bottom = widget[\"y\"] + widget[\"height\"]\n",
    "    box_left   = box[\"x\"]\n",
    "    box_right  = box[\"x\"] + box[\"width\"]\n",
    "    box_top    = box[\"y\"]\n",
    "    box_bottom = box[\"y\"] + box[\"height\"]\n",
    "    if( widget_right >= box_left ) and \\\n",
    "      ( widget_left <= box_right ) and \\\n",
    "      ( widget_bottom >= box_top ) and \\\n",
    "      ( widget_top <= box_bottom ):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def getContainingBox( widget, boxes_arr ):\n",
    "    for box in boxes_arr:\n",
    "        if isInBox( widget, box ):\n",
    "            return box\n",
    "    return None\n",
    "    \n",
    "def getMuralObjects( widgets_arr ):\n",
    "    boxes_arr, labels_arr, stickies_arr = getWidgetsByType( widgets_arr )\n",
    "    for label in labels_arr:\n",
    "        box = getContainingBox( label, boxes_arr )\n",
    "        if( box is not None ):\n",
    "            box[\"label_id\"]       = label[\"id\"]\n",
    "            box[\"label_x\"]        = label[\"x\"]\n",
    "            box[\"label_y\"]        = label[\"y\"]\n",
    "            box[\"class_name\"]     = label[\"text\"]\n",
    "            box[\"top_free_space\"] = label[\"y\"] + label[\"height\"] + 10\n",
    "    exemplars_arr = []\n",
    "    i = 0\n",
    "    while( i < len( stickies_arr ) ):\n",
    "        sticky = stickies_arr[i]\n",
    "        box = getContainingBox( sticky, boxes_arr )\n",
    "        if( box is not None ):\n",
    "            exemplars_arr.append( { \"class_name\" : box[\"class_name\"], \"message\" : sticky[\"text\"] } )\n",
    "            new_y = sticky[\"y\"] + sticky[\"height\"] + 10\n",
    "            if( new_y > box[\"top_free_space\"] ):\n",
    "                box[\"top_free_space\"] = new_y\n",
    "            stickies_arr.pop( i )\n",
    "            continue\n",
    "        i += 1\n",
    "    sorted_class_names = [ \"Stop\", \"Continue\", \"Start\" ]\n",
    "    exemplars_arr = sorted( exemplars_arr, key=lambda d: sorted_class_names.index( d[\"class_name\"] ) )\n",
    "    print( \"Boxes:\" )\n",
    "    for box in boxes_arr:\n",
    "        print( box[\"class_name\"] )\n",
    "    print( \"\\nExemplars:\")\n",
    "    for exemplar in exemplars_arr:\n",
    "        print( \"{:<8}\".format( exemplar[\"class_name\"] ) + \" - \" + exemplar[\"message\"] )\n",
    "    print( \"\\nStickies:\")\n",
    "    for sticky in stickies_arr:\n",
    "        print( sticky[\"text\"] )\n",
    "    return boxes_arr, exemplars_arr, stickies_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxes:\n",
      "Stop\n",
      "Continue\n",
      "Start\n",
      "\n",
      "Exemplars:\n",
      "Stop     - Our daily stand-ups take too long. Let's stop doing those.\n",
      "Stop     - Stop having all-hands meetings, because they don't add any value.\n",
      "Continue - Please let's continue the THINK-Thursday meeting-free afternoon!\n",
      "Continue - Loving the on-site day care\n",
      "Start    - I think we should record our meetings so they could be played back\n",
      "Start    - We should take meeting minutes\n",
      "\n",
      "Stickies:\n",
      "I like the \"updates\" Slack channel - very efficient\n",
      "At my friend's company, they have a lottery for plum parking spots.  We should do something similar!\n",
      "Can we please stop having to sing the national anthem at the start of every day?!\n",
      "Stop forcing everyone to attend the all-hands in person\n",
      "The monthly performance awards are a nice recognition\n",
      "Because of these power outages, we should invest in uninterrupted power supply infrastructure\n"
     ]
    }
   ],
   "source": [
    "g_boxes_arr, g_exemplars_arr, g_stickies_arr = getMuralObjects( g_widgets_arr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section C - Classify sticky notes and move them together in the mural\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/spackows/MURAL-API-Samples/main/images/sample-16_classify-by-exemplars_01.png\" width=\"50%\" title=\"Image of a mural\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step5\"></a>\n",
    "## Step 5: Classify sticky notes\n",
    "Classify sticky notes based on the class exemplars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyStickies( exemplars_arr, stickies_arr ):\n",
    "    base_prompt_text = createBasePromptText( exemplars_arr )\n",
    "    for sticky in stickies_arr:\n",
    "        class_name = classifyMessage( g_model_id, g_prompt_parameters, base_prompt_text, sticky[\"text\"] )\n",
    "        sticky[\"class_name\"] = class_name\n",
    "    sorted_class_names = [ \"Stop\", \"Continue\", \"Start\" ]\n",
    "    stickies_arr = sorted( stickies_arr, key=lambda d: sorted_class_names.index( d[\"class_name\"] ) )\n",
    "    print( \"Results:\\n\" )\n",
    "    for sticky in stickies_arr:\n",
    "        class_name = \"{:<8}\".format( sticky[\"class_name\"] )\n",
    "        print( class_name + \": \" + sticky[\"text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "Stop    : Can we please stop having to sing the national anthem at the start of every day?!\n",
      "Stop    : Stop forcing everyone to attend the all-hands in person\n",
      "Continue: I like the \"updates\" Slack channel - very efficient\n",
      "Continue: The monthly performance awards are a nice recognition\n",
      "Start   : At my friend's company, they have a lottery for plum parking spots.  We should do something similar!\n",
      "Start   : Because of these power outages, we should invest in uninterrupted power supply infrastructure\n"
     ]
    }
   ],
   "source": [
    "classifyStickies( g_exemplars_arr, g_stickies_arr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step6\"></a>\n",
    "## Step 6: Move sticky notes into class boxes in the mural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def moveSticky( auth_token, mural_id, sticky_id, new_x, new_y ):\n",
    "    # https://developers.mural.co/public/reference/updatestickynote\n",
    "    url = \"https://app.mural.co/api/public/v1/murals/\" + mural_id + \"/widgets/sticky-note/\" + sticky_id\n",
    "    headers = { \"Accept\"        : \"application/json\", \n",
    "                \"Content-Type\"  : \"application/json\", \n",
    "                \"Authorization\" : \"Bearer \" + auth_token }\n",
    "    parms = { \"x\" : new_x, \"y\" : new_y }\n",
    "    response = requests.request( \"PATCH\", url, headers = headers, json = parms )\n",
    "    response_json = json.loads( response.text )\n",
    "    msg = \"\"\n",
    "    if \"code\" in response_json:\n",
    "        msg += response_json[\"code\"] + \" \"\n",
    "    if \"message\" in response_json:\n",
    "        msg += response_json[\"message\"]\n",
    "    if msg != \"\":\n",
    "        print( \"[ \" + sticky_id + \" ] \" + msg )\n",
    "\n",
    "def moveStickyToBox( auth_token, mural_id, sticky, box ):\n",
    "    y = box[\"top_free_space\"]\n",
    "    min_x = box[\"x\"]\n",
    "    max_x = box[\"x\"] + box[\"width\"] - ( 0.8 * sticky[\"width\"] )\n",
    "    x = random.uniform( min_x, max_x )\n",
    "    moveSticky( auth_token, mural_id, sticky[\"id\"], x, y )\n",
    "    return x, y\n",
    "\n",
    "def boxesJSON( boxes_arr ):\n",
    "    boxes_json = {}\n",
    "    for box in boxes_arr:\n",
    "        class_name = box[\"class_name\"]\n",
    "        boxes_json[ class_name ] = box\n",
    "    return boxes_json\n",
    "\n",
    "def moveStickiesToClassBoxes( auth_token, mural_id, boxes_arr, stickies_arr ):\n",
    "    boxes_json = boxesJSON( boxes_arr )\n",
    "    for sticky in stickies_arr:\n",
    "        class_name = sticky[\"class_name\"]\n",
    "        box = boxes_json[ class_name ]\n",
    "        new_x, new_y = moveStickyToBox( auth_token, mural_id, sticky, box )\n",
    "        box[\"top_free_space\"] = new_y + sticky[\"height\"] + 10\n",
    "    print( \"Done!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "\n",
    "# Quick!  After running this cell, switch to your browser \n",
    "# tab where the mural is to see the change\n",
    "# ...\n",
    "\n",
    "moveStickiesToClassBoxes( g_auth_token, g_mural_id, g_boxes_arr, g_stickies_arr )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something like this:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/spackows/MURAL-API-Samples/main/images/sample-16_classify-by-exemplars_04.gif\" width=\"50%\" title=\"Image of a mural\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
